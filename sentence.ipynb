{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4e1379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ever/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6229bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.1.0)\n",
      "Requirement already satisfied: requests in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.38.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: click in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43c87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ever/anaconda3/envs/cse256/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4281f2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81638d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test_y = pd.read_csv(\"data/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecc7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    patterns = [\n",
    "        r'http\\S+',\n",
    "        r'\\bhttps?://[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+\\b',\n",
    "        r'[^\\w\\s]', \n",
    "        r'\\d',\n",
    "        r'[\\u4e00-\\u9fff]+',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a5860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].map(clean_text)\n",
    "train['sentences'] = train['comment_text'].map(sent_tokenize)\n",
    "test['comment_text'] = test['comment_text'].map(clean_text)\n",
    "test['sentences'] = test['comment_text'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8789cee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Explanation Why the edits made under my usern...\n",
       "1    [D aww He matches this background colour I m s...\n",
       "2    [Hey man I m really not trying to edit war It ...\n",
       "3    [More I can t make any real suggestions on imp...\n",
       "4    [You sir are my hero Any chance you remember w...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentences'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470179f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Yo bitch Ja Rule is more succesful then you l...\n",
       "1            [From RfC The title is fine as it is IMO]\n",
       "2                     [Sources Zawe Ashton on Lapland]\n",
       "3    [If you have a look back at the source the inf...\n",
       "4           [I don t anonymously edit articles at all]\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sentences'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207e3909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "sentences = train['sentences'].apply(lambda x: (x, '') if x is not None else ([], '')).tolist()\n",
    "\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "with tqdm(total=len(sentences), desc=\"Encoding\", leave=False, dynamic_ncols=True) as pbar:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a1d468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159571, 384])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce2e8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "X = embeddings.cpu().numpy()\n",
    "y = train[class_labels]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89d4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin= mlb.fit_transform(y_train)\n",
    "y_valid_bin = mlb.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4985bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = y_train[class_labels].values.astype(int)\n",
    "y_valid_binary = y_valid[class_labels].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbac2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.85336734\n",
      "Validation score: 0.909839\n",
      "Iteration 2, loss = 0.34842739\n",
      "Validation score: 0.914225\n",
      "Iteration 3, loss = 0.33131532\n",
      "Validation score: 0.913050\n",
      "Iteration 4, loss = 0.32121517\n",
      "Validation score: 0.915322\n",
      "Iteration 5, loss = 0.31263576\n",
      "Validation score: 0.915557\n",
      "Iteration 6, loss = 0.30526232\n",
      "Validation score: 0.913912\n",
      "Iteration 7, loss = 0.29738693\n",
      "Validation score: 0.915322\n",
      "Iteration 8, loss = 0.29201498\n",
      "Validation score: 0.914539\n",
      "Iteration 9, loss = 0.28611544\n",
      "Validation score: 0.915479\n",
      "Iteration 10, loss = 0.28031981\n",
      "Validation score: 0.913442\n",
      "Iteration 11, loss = 0.27498306\n",
      "Validation score: 0.916967\n",
      "Iteration 12, loss = 0.27012680\n",
      "Validation score: 0.911562\n",
      "Iteration 13, loss = 0.26524471\n",
      "Validation score: 0.913207\n",
      "Iteration 14, loss = 0.26060188\n",
      "Validation score: 0.914147\n",
      "Iteration 15, loss = 0.25676832\n",
      "Validation score: 0.913364\n",
      "Iteration 16, loss = 0.25113369\n",
      "Validation score: 0.914617\n",
      "Iteration 17, loss = 0.24608546\n",
      "Validation score: 0.907645\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 32, 16, 6),\n",
       "              max_iter=50, n_iter_no_change=5, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32, 16, 6),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=50,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880b19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "sentences = test['sentences'].apply(lambda x: (x, '') if x is not None else ([], '')).tolist()\n",
    "\n",
    "batch_size = 32\n",
    "test_embeddings = []\n",
    "with tqdm(total=len(sentences), desc=\"Encoding\", leave=False, dynamic_ncols=True) as pbar:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "        test_embeddings.append(batch_embeddings)\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "test_embeddings = torch.cat(test_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8bb7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([153164, 384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdfadbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = clf.predict_proba(test_embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e2cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_prob:  [[0.94930726 0.42651013 0.93091196 0.06396484 0.819107   0.38829646]\n",
      " [0.00005219 0.00000001 0.00000481 0.00000026 0.00000344 0.00000055]\n",
      " [0.00013198 0.00000003 0.00000928 0.00000096 0.00000622 0.00000153]\n",
      " ...\n",
      " [0.0001021  0.00000002 0.00003498 0.00000009 0.00000922 0.00000067]\n",
      " [0.00441968 0.00003071 0.00052268 0.0004029  0.00054803 0.0006298 ]\n",
      " [0.9231681  0.00589816 0.7931181  0.00025852 0.40623775 0.00238886]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(\"y_test_prob: \", y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b397d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = pd.DataFrame({'id': test.index})  # Use index as 'id' column\n",
    "submission = pd.concat([id, pd.DataFrame(y_test_prob, columns=class_labels)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "812c9ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.949307</td>\n",
       "      <td>4.265101e-01</td>\n",
       "      <td>9.309120e-01</td>\n",
       "      <td>6.396484e-02</td>\n",
       "      <td>8.191070e-01</td>\n",
       "      <td>3.882965e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.072119e-08</td>\n",
       "      <td>4.805834e-06</td>\n",
       "      <td>2.645486e-07</td>\n",
       "      <td>3.437027e-06</td>\n",
       "      <td>5.519983e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>3.304054e-08</td>\n",
       "      <td>9.283026e-06</td>\n",
       "      <td>9.581056e-07</td>\n",
       "      <td>6.221908e-06</td>\n",
       "      <td>1.526719e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.894770e-11</td>\n",
       "      <td>4.491700e-08</td>\n",
       "      <td>7.131820e-09</td>\n",
       "      <td>8.381811e-08</td>\n",
       "      <td>5.437568e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>3.674641e-06</td>\n",
       "      <td>3.978441e-04</td>\n",
       "      <td>2.260107e-05</td>\n",
       "      <td>1.194101e-03</td>\n",
       "      <td>2.516105e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic  severe_toxic       obscene        threat        insult  \\\n",
       "0   0  0.949307  4.265101e-01  9.309120e-01  6.396484e-02  8.191070e-01   \n",
       "1   1  0.000052  1.072119e-08  4.805834e-06  2.645486e-07  3.437027e-06   \n",
       "2   2  0.000132  3.304054e-08  9.283026e-06  9.581056e-07  6.221908e-06   \n",
       "3   3  0.000002  3.894770e-11  4.491700e-08  7.131820e-09  8.381811e-08   \n",
       "4   4  0.010063  3.674641e-06  3.978441e-04  2.260107e-05  1.194101e-03   \n",
       "\n",
       "   identity_hate  \n",
       "0   3.882965e-01  \n",
       "1   5.519983e-07  \n",
       "2   1.526719e-06  \n",
       "3   5.437568e-09  \n",
       "4   2.516105e-05  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca8041",
   "metadata": {},
   "source": [
    "the private score is 96.83% on the Kaggle test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse256",
   "language": "python",
   "name": "cse256"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
